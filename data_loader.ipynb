{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from PIL import Image\n",
    "import torch.utils.data as data\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import numpy as np\n",
    "import lmdb\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def default_loader(path):\n",
    "    try:\n",
    "        im = Image.open(path).convert('RGB')\n",
    "        print (\"Hello\") \n",
    "        return im\n",
    "    except:\n",
    "        print(\"...\", file=sys.stderr)\n",
    "        return Image.new('RGB', (224, 224), 'white')\n",
    "        template = \"An exception of type {0} occurred. Arguments:\\n{1!r}\"\n",
    "        message = template.format(type(ex).__name__, ex.args)\n",
    "        print(message)\n",
    "        print('Here\\'s the path {}'.format(path))\n",
    "        #pdb.set_trace()\n",
    "        return Image.new('RGB', (224, 224), 'white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageLoader(data.Dataset):\n",
    "    def __init__(self, img_path, transform=None, target_transform=None,\n",
    "                 loader=default_loader, square=False, data_path=None, partition=None):\n",
    "        if data_path == None:\n",
    "            raise Exception('No data path specified.')\n",
    "\n",
    "        if partition is None:\n",
    "            raise Exception('Unknown partition type %s.' % partition)\n",
    "        else:\n",
    "            self.partition = partition\n",
    "        # Open the LMDB files.\n",
    "        self.env = lmdb.open(os.path.join(data_path, partition + '_lmdb'), max_readers=1, readonly=True, lock=False,\n",
    "                             readahead=False, meminit=False)\n",
    "        with open(os.path.join(data_path, partition + '_keys.pkl'), 'rb') as f:\n",
    "            self.ids = pickle.load(f)\n",
    "        \n",
    "        self.square = square\n",
    "        self.imgPath = img_path\n",
    "        self.mismtch = 0.8\n",
    "        self.maxInst = 20\n",
    "        \n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.loader = loader\n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "        recipId = self.ids[index]\n",
    "        # we force 80 percent of them to be a mismatch\n",
    "        if self.partition == 'train':\n",
    "            match = np.random.uniform() > self.mismtch\n",
    "        elif self.partition == 'val' or self.partition == 'test':\n",
    "            match = True\n",
    "        else:\n",
    "            raise 'Partition name not well defined'\n",
    "        \n",
    "        target = match and 1 or -1\n",
    "        \n",
    "        with self.env.begin(write=False) as txn:\n",
    "            serialized_sample = txn.get(self.ids[index])\n",
    "        sample = pickle.loads(serialized_sample)\n",
    "        imgs = sample['imgs']\n",
    "    \n",
    "        # image\n",
    "        if target == 1:\n",
    "            if self.partition == 'train':\n",
    "                # We do only use the first five images per recipe during training\n",
    "                imgIdx = np.random.choice(range(min(5, len(imgs))))\n",
    "            else:\n",
    "                imgIdx = 0\n",
    "            loader_path = [imgs[imgIdx]['id'][i] for i in range(4)]\n",
    "            loader_path = os.path.join(*loader_path)\n",
    "            path = os.path.join(self.imgPath, self.partition, loader_path, imgs[imgIdx]['id'])\n",
    "        else:\n",
    "            # we randomly pick one non-matching image\n",
    "            all_idx = range(len(self.ids))\n",
    "            rndindex = np.random.choice(all_idx)\n",
    "            while rndindex == index:\n",
    "                rndindex = np.random.choice(all_idx)  # pick a random index\n",
    "\n",
    "            with self.env.begin(write=False) as txn:\n",
    "                serialized_sample = txn.get(self.ids[rndindex])\n",
    "\n",
    "            rndsample = pickle.loads(serialized_sample)\n",
    "            rndimgs = rndsample['imgs']\n",
    "\n",
    "            if self.partition == 'train':  # if training we pick a random image\n",
    "                # We do only use the first five images per recipe during training\n",
    "                imgIdx = np.random.choice(range(min(5, len(rndimgs))))\n",
    "            else:\n",
    "                imgIdx = 0\n",
    "\n",
    "            path = self.imgPath + rndimgs[imgIdx]['id']\n",
    "        \n",
    "       \n",
    "        # instructions\n",
    "        \n",
    "        instrs = sample['instruct']\n",
    "        instr_vec_sent = instrs[0]\n",
    "        instr_vec_word = instrs[1]\n",
    "        \n",
    "#         t_inst = np.zeros((self.maxInst, np.shape(instrs)[1]), dtype=np.float32)\n",
    "#         t_inst[:itr_ln][:] = instrs\n",
    "        instr_vec_sent = torch.FloatTensor(instr_vec_sent)\n",
    "        instr_vec_word = torch.FloatTensor(instr_vec_word)\n",
    "        print (instr_vec_sent)\n",
    "        print (instr_vec_word)\n",
    "        return\n",
    "        # ingredients\n",
    "        ingrs = sample['ingrs'].astype(int)\n",
    "        ingrs = torch.LongTensor(ingrs)\n",
    "        igr_ln = max(np.nonzero(sample['ingrs'])[0]) + 1\n",
    "\n",
    "        # load image\n",
    "        img = self.loader(path)\n",
    "\n",
    "        if self.square:\n",
    "            img = img.resize(self.square)\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        rec_class = sample['classes'] - 1\n",
    "        rec_id = self.ids[index]\n",
    "\n",
    "        if target == -1:\n",
    "            img_class = rndsample['classes'] - 1\n",
    "            img_id = self.ids[rndindex]\n",
    "        else:\n",
    "            img_class = sample['classes'] - 1\n",
    "            img_id = self.ids[index]\n",
    "        \n",
    "        if self.partition == 'train':\n",
    "            return [img, ingrs, igr_ln], [target]\n",
    "            #return [img, instrs, itr_ln, ingrs, igr_ln], [target]\n",
    "        else:\n",
    "            return [img, ingrs, igr_ln], [target, img_id, rec_id]\n",
    "            #return [img, instrs, itr_ln, ingrs, igr_ln], [target, img_id, rec_id]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yifu/anaconda3/envs/pytorch2.7/lib/python2.7/site-packages/torchvision-0.2.1-py2.7.egg/torchvision/transforms/transforms.py:188: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n"
     ]
    }
   ],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "IMG_PATH = '/home/yifu/Documents/Mycode/python/hierarchicalRNN/jasha/'\n",
    "# GIve the path for the LMDB files that were created.\n",
    "DATA_PATH = '/home/yifu/Documents/Mycode/python/hierarchicalRNN/jasha/lmdb/'\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "WORKERS = 30\n",
    "BATCH_SIZE = 160\n",
    "i1 = ImageLoader(IMG_PATH,\n",
    "            transforms.Compose([\n",
    "            transforms.Scale(256), # rescale the image keeping the original aspect ratio\n",
    "            transforms.CenterCrop(256), # we get only the center of that rescaled\n",
    "            transforms.RandomCrop(224), # random crop within the center crop\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ]),\n",
    "        data_path=DATA_PATH,\n",
    "        partition='train')\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "        i1,\n",
    "        batch_size=BATCH_SIZE, shuffle=True,\n",
    "        num_workers=WORKERS, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############Testing#########################\n",
    "data_path = '/home/yifu/Documents/Mycode/python/hierarchicalRNN/jasha/lmdb/'\n",
    "partition = 'train'\n",
    "env = lmdb.open(os.path.join(data_path, partition + '_lmdb'), max_readers=1, readonly=True, lock=False,\n",
    "                             readahead=False, meminit=False)\n",
    "with open(os.path.join(data_path, partition + '_keys.pkl'), 'rb') as f:\n",
    "    ids = pickle.load(f)\n",
    "loader = default_loader\n",
    "mismtch = 0.8\n",
    "index = 100\n",
    "recipId = ids[index]\n",
    "        # we force 80 percent of them to be a mismatch\n",
    "if partition == 'train':\n",
    "    match = np.random.uniform() > mismtch\n",
    "target = match and 1 or -1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Environment at 0x7fbae872c030>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch2.7]",
   "language": "python",
   "name": "conda-env-pytorch2.7-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
